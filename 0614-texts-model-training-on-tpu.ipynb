{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nprint(tf.version.VERSION)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-14T00:31:47.211447Z","iopub.execute_input":"2022-06-14T00:31:47.213483Z","iopub.status.idle":"2022-06-14T00:31:53.052428Z","shell.execute_reply.started":"2022-06-14T00:31:47.213375Z","shell.execute_reply":"2022-06-14T00:31:53.051441Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# detect and init the TPU\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver()\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)\n# instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)","metadata":{"execution":{"iopub.status.busy":"2022-06-14T00:31:53.054011Z","iopub.execute_input":"2022-06-14T00:31:53.054294Z","iopub.status.idle":"2022-06-14T00:31:59.051517Z","shell.execute_reply.started":"2022-06-14T00:31:53.054264Z","shell.execute_reply":"2022-06-14T00:31:59.050845Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"text1 = open('../input/mydata/Crimson Sabre.txt',encoding='utf-8').read()\ntext2= open('../input/mydata/Island of No return-Xia Ko Shin-Hap Kak Hang.txt', encoding='utf-8').read()\ntext3 =open('../input/mydata/SheDioYiXiongChuan.txt',encoding='utf-8').read()\ntext4 =open('../input/mydata/TeinLongBaBu.txt',encoding='utf-8').read()\ntext5 = open('../input/mydata/The Flying Fox of Snowy Mountain.txt',encoding='utf-8').read()\ntext6= open('../input/mydata/White Horse Neighing in the West Wind.txt', encoding='utf-8').read()\ntext7 =open('../input/mydata/XIaoaoginhu.txt',encoding='utf-8').read()\ntext8 =open('../input/mydata/yiteintulonggy.txt',encoding='utf-8').read()\ntext= text1 + text2 +text3 +text4+ text5 + text6 +text7 +text8","metadata":{"execution":{"iopub.status.busy":"2022-06-14T00:32:04.439910Z","iopub.execute_input":"2022-06-14T00:32:04.440263Z","iopub.status.idle":"2022-06-14T00:32:04.873907Z","shell.execute_reply.started":"2022-06-14T00:32:04.440232Z","shell.execute_reply":"2022-06-14T00:32:04.872962Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"w = len(set(text))\ntokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=w,char_level=True,filters='')\ntokenizer.fit_on_texts(text)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-14T00:32:09.962293Z","iopub.execute_input":"2022-06-14T00:32:09.962607Z","iopub.status.idle":"2022-06-14T00:32:19.215484Z","shell.execute_reply.started":"2022-06-14T00:32:09.962571Z","shell.execute_reply":"2022-06-14T00:32:19.214712Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# 方便說明，實際上我們會用更大的值來讓模型從更長的序列預測下個中文字\nSEQ_LENGTH = 10  # 數字序列長度\nBATCH_SIZE = 128 # 幾筆成對輸入/輸出\ntext_as_int = tokenizer.texts_to_sequences([text])[0]\n\n# 我們利用 from_tensor_slices 將其轉變成 TensorFlow 最愛的 Tensor\ncharacters = tf.data.Dataset.from_tensor_slices(text_as_int)\n\nprint(type(characters))\n# 將被以數字序列表示的天龍八部文本拆成多個長度為 (SEQ_LENGTH(10)+1) 的序列\n# 並將最後長度不滿 SEQ_LENGTH 的序列捨去\nsequences = characters.batch(SEQ_LENGTH + 1,drop_remainder=True)\nprint(sequences)","metadata":{"execution":{"iopub.status.busy":"2022-06-14T00:32:22.776796Z","iopub.execute_input":"2022-06-14T00:32:22.777067Z","iopub.status.idle":"2022-06-14T00:32:42.625404Z","shell.execute_reply.started":"2022-06-14T00:32:22.777040Z","shell.execute_reply":"2022-06-14T00:32:42.624531Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# 天龍八部全文所包含的成對輸入/輸出的數量\nsteps_per_epoch = \\\n    len(text_as_int) // SEQ_LENGTH\nprint(\"成對輸入輸出數量:\",steps_per_epoch)\n# 成對輸入輸出數量 414632 （4146323/10=414632）\n\n# 這個函式專門負責把一個序列拆成兩個序列，分別代表輸入與輸出\ndef build_seq_pairs(chunk):\n    input_text = chunk[:-1]\n    target_text = chunk[1:]\n    return input_text, target_text\n# 將每個從文本擷取出來的序列套用上面定義的函式，拆成兩個數字序列\n# 作為輸入／輸出序列再將得到的所有數據隨機打亂順序最後再一次拿出 BATCH_SIZE（128）筆數據\n# ds作為模型一次訓練步驟的所使用的資料\nds = sequences\\\n    .map(build_seq_pairs)\\\n    .shuffle(steps_per_epoch)\\\n    .batch(BATCH_SIZE, \n           drop_remainder=True)\n\nprint(\"ds.map:\",ds.map)\nprint(\"ds.map 取第一個值：\",ds.take(1))","metadata":{"execution":{"iopub.status.busy":"2022-06-14T00:32:51.418020Z","iopub.execute_input":"2022-06-14T00:32:51.418331Z","iopub.status.idle":"2022-06-14T00:32:51.512014Z","shell.execute_reply.started":"2022-06-14T00:32:51.418299Z","shell.execute_reply":"2022-06-14T00:32:51.511363Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# 超參數\nEMBEDDING_DIM = 512\nRNN_UNITS = 1024\nLEARNING_RATE = 0.001","metadata":{"execution":{"iopub.status.busy":"2022-06-14T00:33:07.731654Z","iopub.execute_input":"2022-06-14T00:33:07.731945Z","iopub.status.idle":"2022-06-14T00:33:07.736669Z","shell.execute_reply.started":"2022-06-14T00:33:07.731911Z","shell.execute_reply":"2022-06-14T00:33:07.735914Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# instantiating the model in the strategy scope creates the model on the TPU\nwith tpu_strategy.scope():\n    model = tf.keras.Sequential()\n    model.add(tf.keras.layers.Embedding(input_dim=w,output_dim=EMBEDDING_DIM,batch_input_shape=[BATCH_SIZE, None]))\n\n    # LSTM層，負責將序列數據依序讀入並做處理  原本在GPU上是設stateful=true, TPU上設為空\n    model.add(tf.keras.layers.LSTM(units=RNN_UNITS, return_sequences=True, stateful='', recurrent_initializer='glorot_uniform'))\n\n    model.add(tf.keras.layers.Dense(w))\n\n    def loss(y_true, y_pred):\n        return tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)\n\n    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE), loss=loss)","metadata":{"execution":{"iopub.status.busy":"2022-06-14T00:33:12.232419Z","iopub.execute_input":"2022-06-14T00:33:12.233227Z","iopub.status.idle":"2022-06-14T00:33:13.228526Z","shell.execute_reply.started":"2022-06-14T00:33:12.233168Z","shell.execute_reply":"2022-06-14T00:33:13.227602Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 200 # 決定看幾篇天龍八部文本\nhistory = model.fit(\n    ds, # 前面使用 tf.data 建構的資料集\n    epochs=EPOCHS\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-14T00:33:21.801173Z","iopub.execute_input":"2022-06-14T00:33:21.801580Z","iopub.status.idle":"2022-06-14T04:17:19.105480Z","shell.execute_reply.started":"2022-06-14T00:33:21.801536Z","shell.execute_reply":"2022-06-14T04:17:19.104639Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model.save(\"myModel_8books_10Words_200Epochs.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-06-14T04:17:19.759736Z","iopub.execute_input":"2022-06-14T04:17:19.759955Z","iopub.status.idle":"2022-06-14T04:17:20.455135Z","shell.execute_reply.started":"2022-06-14T04:17:19.759929Z","shell.execute_reply":"2022-06-14T04:17:20.454187Z"},"trusted":true},"execution_count":11,"outputs":[]}]}