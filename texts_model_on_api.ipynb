{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = open('novel\\天龍八部.txt',encoding='utf-8').read()\n",
    "text2= open('novel\\射雕英雄傳.txt', encoding='utf-8').read()\n",
    "text3 =open('novel\\笑傲江湖.txt',encoding='utf-8').read()\n",
    "text4 =open('novel\\倚天屠龍記.txt',encoding='utf-8').read()\n",
    "text5 = open('novel\\白馬嘯西風.txt',encoding='utf-8').read()\n",
    "text6= open('novel\\俠客行.txt', encoding='utf-8').read()\n",
    "text7 =open('novel\\雪山飛狐.txt',encoding='utf-8').read()\n",
    "text8 =open('novel\\碧血劍.txt',encoding='utf-8').read()\n",
    "text= text1 + text2 +text3 +text4 +text5 + text6+ text7 + text8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = len(set(text))\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "        num_words=w,char_level=True,filters='')\n",
    "tokenizer.fit_on_texts(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (1, None, 512)            2692096   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (1, None, 1024)           6295552   \n",
      "                                                                 \n",
      " dense (Dense)               (1, None, 5258)           5389450   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,377,098\n",
      "Trainable params: 14,377,098\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 512\n",
    "RNN_UNITS = 1024\n",
    "BATCH_SIZE = 1\n",
    "# w =4880\n",
    "# 專門用來做生成的模型容器\n",
    "infer_model = tf.keras.Sequential()\n",
    "\n",
    "# 詞嵌入層\n",
    "infer_model.add(\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=w, \n",
    "        output_dim=EMBEDDING_DIM,\n",
    "        batch_input_shape=[BATCH_SIZE, None]\n",
    "        ))\n",
    "\n",
    "# LSTM 層\n",
    "infer_model.add(tf.keras.layers.LSTM(units=RNN_UNITS, return_sequences=True, stateful=True))\n",
    "\n",
    "# 全連接層\n",
    "infer_model.add(tf.keras.layers.Dense(w))\n",
    "\n",
    "infer_model.build(tf.TensorShape([1, None]))\n",
    "infer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string,words_number,temperature): \n",
    "  # Number of characters to generate\n",
    "  num_generate = words_number #字數調整，前端更改\n",
    "\n",
    "  input_eval = tokenizer.texts_to_sequences([start_string])[0]\n",
    "  input_eval = tf.expand_dims(input_eval, 0)\n",
    "  # Empty string to store our results\n",
    "  text_generated = []\n",
    "  temperature = temperature\n",
    "\n",
    "  # Here batch size == 1\n",
    "  model.reset_states()\n",
    "  for i in range(num_generate):\n",
    "      predictions = model(input_eval)\n",
    "      # remove the batch dimension\n",
    "      predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "      # using a categorical distribution to predict the character returned by the model\n",
    "      predictions = predictions / temperature\n",
    "      predicted_id = tf.random.categorical(predictions,\n",
    "      num_samples=1)[-1,0].numpy()\n",
    "\n",
    "      # We pass the predicted character as the next input to the model\n",
    "      # along with the previous hidden state\n",
    "      input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "      text_generated.append(tokenizer.index_word[predicted_id])\n",
    "\n",
    "  return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_path='myModel_8books_10Words_200Epochs.h5'\n",
    "infer_model.load_weights(h5_path)\n",
    "infer_model.build(\n",
    "    tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "掌門人皮皮蝦右手一揮掌勁一使，更是虛招，便即明白是他們打扮之德，何以連擬瓜邪派令狐沖意說的。是以大叉上山，便是為我們下毒之後，當真是一個人，圖中一腕尤叩山睜，自是大為震驚。\n",
      "　　貝海石道：“姓袁的，你說要報仇，還不是一題？”\n",
      "　　\n"
     ]
    }
   ],
   "source": [
    "# 呼叫預測函數\n",
    "'''\n",
    "起始示範語句：\n",
    "1.少俠皮皮蝦一登上光明頂\n",
    "2.掌門人皮皮蝦手一揮掌勁一使，\n",
    "3.掌門人皮皮蝦雙手一揮掌勁一使，\n",
    "'''\n",
    "results = generate_text(infer_model, start_string=\"掌門人皮皮蝦右手一揮掌勁一使，\",words_number=100,temperature=0.6)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(generate_text(infer_model, start_string=\"少俠盧瑞山身子一躍\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on all addresses (0.0.0.0)\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.161.48:5000 (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import flask\n",
    "from flask import jsonify, request\n",
    "from flask_cors import CORS\n",
    "\n",
    "app = flask.Flask(__name__)\n",
    "#app.config[\"DEBUG\"] = False\n",
    "app.config[\"JSON_AS_ASCII\"] = False\n",
    "cors = CORS(app, resources={r\"/*\": {\"origins\": \"*\"}})\n",
    "\n",
    "@app.route('/', methods=['GET'])\n",
    "def home():\n",
    "    return \"<h1>Hello Flask!</h1>\"\n",
    "\n",
    "@app.route('/text_gen', methods=['GET'])\n",
    "def text_gen():\n",
    "    if 'start_string' in request.args:\n",
    "        start_string = request.args['start_string']\n",
    "        words_number=int(request.args.get('words_number'))\n",
    "        temperature=float(request.args.get('temperature'))\n",
    "        print(start_string,words_number,temperature)\n",
    "    else:\n",
    "        return \"Error: No city_name provided. Please specify a city_name.\"\n",
    "    \n",
    "    results = []    \n",
    "    start_time = time.time()    \n",
    "    results = generate_text(infer_model, start_string=start_string,words_number=words_number,temperature=temperature) \n",
    "    #print(results)\n",
    "    end_time = time.time()\n",
    "    print('推論花了：',end_time - start_time,'秒的時間')\n",
    "    return results\n",
    "\n",
    "app.run(host='0.0.0.0')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "metadata": {
   "interpreter": {
    "hash": "05ece30799c2dcdac4c13b3af20453da19de8df0d9a1de52cff7e0b6e1e82bdd"
   }
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "3a8d20506be82a4461f9b41041c14fdfe08e8897388d050f9d1ea4a80103d22a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
